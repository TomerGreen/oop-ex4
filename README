tomerg
idobar


=============================
=      File description     =
=============================

BinarySearchTree.java - an abstract class implementing an ordered binary tree, of which an AVL tree is a sub-class.
This file also includes the Node and Iterator nested classes.
AvlTree.java - The AVL tree class and nested classes.

=============================
=          Design           =
=============================

*  For purposes of extendability we chose to implement AvlTree as a class inheriting from an abstract BinarySearchTree
class. This is because all of the fields and nested classes, and some of the methods of AvlTree can be applied to any
ordered binary tree if one chooses to implement a new class.

*  We decided to nest the Node and BinaryTreeIterator classes in the abstract BinarySearchTree class. This is because
objects in these classes can be used by any ordered binary tree. Additionally, we do not want Node or Iterator
instances to be created outside the context of an actual binary search tree. It also enabled us to discard some getters
and setters for these classes, since BinarySearchTree has access to their private fields.


=============================
=  Implementation details   =
=============================

*  In order to refrain from having to probe the tree twice in every add operation, we wrote a helper function that,
when given a value, returns either a node with that value, or the parent node of that value were it added to the tree.
We can then check if the value exists and get the node we should attach it to in one probing.

*  We decided that the Node depth field will only be updated when searching for a value in the tree, in the case that it
is found. This is because insertion and deletion functions manipulate node depths often, but do not make use of the
field. We only need it when contains() is called and the value is found.

=============================
=   Answers to Questions    =
=============================

add implementation:
* First, we use expectedParent, which finds the proper location of newValue incase it is not already in the
  tree, and returns null if the value is already in tree or if the tree is empty.

* if expectedParent returns null, and the root is also null, the tree is empty and we create the root with
  newValue, update the size and return true.
* if expectedParent returns null but the root isn't null,, the value is already in the tree and we return
  false.
* else, we add the value:
	* we check if newValue is bigger or smaller than its parent value, and add it at the proper place.
	* we call fixTree(newNode), which adjusts the heights and checks for violations until reaching the root.
	* if a violation is found we fix it and exit the method, as one call to add and only incur one violation.
	* update the size return true

Add takes O(logn + logn) = O(logn)   --> one log(n) to descend to the right place, and one log(n) to climb
back up.


delete implementation:
* First we use valueToNode on toDelete to check if we have a node with toDelete's value.
* If we do not, valueToNode returns null and we exit the method.
* Else, we check if the node is a leaf, single childed or double childed, and act accoridngly.
All cases use the method reBalanceTree(father), which checks for violations on the father node,
and fixes them. It is different from fixTree because fixTree is given a leaf and calculates its father
and grandfather, and reBalanceTree is given a father and calculates its (highest) son and (highest) grandson.
Back to the three cases of the toDelete node:
	if leaf, we call leafDelete:
		* if it is also the root, we change the root to null and udpate the size.
		* else we change its father's pointer to null, update the size and call reBalanceTree.
	if single childed, we call singleChildDelete:
		* if toDelete is also the root, it makes the child the root and updates the size.
		* else, it changes toDelete's father to point at toDelete's single child
		* updates the size, and calls reBalanceTree on toDelete's father.
	if double childed:
		* it finds a successor, and swaps the successor and toDelete.
		* if after the swap toDelete is not a leaf, it can only have a right son, otherwise it wouldn't be
		  a successor. So in this case we essentially have a single chlilded case, and so we call
		  singleChildDelete
		* else, toDelete is now a leaf, so we call leafDelete.

running time of delete = O(logn + logn) = O(logn). One log(n) to find the right node, and one log(n) to fix
violations.

Both add and delete methods use the checkViolations, which is the method that checks and fixes all violations
They also both use fixHeight, which fixes the height of a node.


Answers to Theoretical Questions:

5.1) 8 3 10 2 5 9 11 12 1 4 6 7

5.2) 1. O(nlogn). We have n insertion, and we prove the tree with running time bounded by O(nlogn) in each of them,
when the time to reorder the tree is also asymptotically bounded nlogn.
2. O(n) if the array is sorted, and each time we insert a value whose parent is a leaf so that no reogranization is
needed (we can access that integer's index directly).

5.3) 1. O(nlogn), for same reason as with array. Duplicating the node received takes O(1).
2. O(n) If the iterator returns values as we would have picked them in the case of the array (median of leaves).

5.4) 1. We're performing findMinNodes in O(n) since the recursion relation is T(h)=T(h-1)+T(h-2).
2. One can probably calculate the h'th value in a Fibonacci series and get the same result, hence a non-binary
running time of O(1).